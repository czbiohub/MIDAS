# -*- mode: Snakemake -*-
#
# Build customer MIDAS database.
#
# Chunyu Zhao 2019-06-26

import os, subprocess, sys, shutil, gzip
from pathlib import Path
from midas import utility
import Bio.SeqIO
from collections import defaultdict
from functools import reduce
from operator import concat

project_dir = Path("/mnt/chunyu20TB/midas-iggdb/IGGdb/v2.0.0")
toc_fp = str(project_dir/"genomes2species.tab")

mapfile_fp = str(project_dir/"mapfile")
phyeco_hmm_fp = "/mnt/chunyu20TB/midas-iggdb/IGGdb/v2.0.0/phyeco.hmm"

temp_path = Path(str(project_dir/"temp"))
repgenome_path = Path(str(project_dir/"clean_set"))
species_dir = Path(str(project_dir/"species"))
genomes_dir = Path(str(project_dir/"genomes"))
prokka_dir = Path(str(project_dir/"prokka"))
pangenomes_dir = Path(str(project_dir/"pangenomes"))


GENOMES = {}
SPECIES = defaultdict(list)
Gpath = {}
with open(toc_fp) as f:
    next(f)
    for line in f:
        genome_id = line.rstrip('\n').split('\t')[1]
        species_id = line.rstrip('\n').split('\t')[-1]
        GENOMES[genome_id] = str(species_id)
        SPECIES[species_id].append(str(genome_id))
        Gpath[genome_id] = "%s/clean_set/%s" % (str(project_dir), str(species_id))

if not os.path.isfile(mapfile_fp):
    with open(mapfile_fp, "w") as out:
        out.write('\t'.join(["genome_id", "species_id", "rep_genome"]) + '\n')
        for genome in GENOMES.keys():
            if GENOMES[genome] == genome:
                line = [genome, GENOMES[genome], 1]
            else:
                line = [genome, GENOMES[genome], 0]
            out.write('\t'.join(map(str, line)) + '\n')

rule species_map_genome:
    input:
        str(repgenome_path/"{species}"/"{species}.fna.lz4")
    output:
        str(project_dir/"genomes"/"{species}.fna.lz4")
    params:
        src = str(repgenome_path/"{species}"),
        dst = str(project_dir/"genomes")
    run:
        genomes = SPECIES[wildcards['species']]
        src = params['src']
        dst = params['dst']
        for genome in genomes:
            f = "%s/%s.fna.lz4" % (src, genome)
            t = "%s/%s.fna.lz4" % (dst, genome)
            shutil.copyfile(f, t)


GENOMES_DICT = GENOMES
SPECIES_ALL = list(SPECIES.keys())
GENOMES = list(GENOMES.keys())

SPECIES_0701 = ["GUT_GENOME147854","GUT_GENOME001120","GUT_GENOME096063","GUT_GENOME096203", \
            "GUT_GENOME147678", "GUT_GENOME001115","GUT_GENOME095967","GUT_GENOME000152",\
            "GUT_GENOME095021", "GUT_GENOME000092","GUT_GENOME140074","GUT_GENOME140808",
            "GUT_GENOME140826"]

TEST_SPECIES = ["GUT_GENOME125418", "GUT_GENOME011056"]
TEST_GENOMES = reduce(concat, [list(SPECIES[species]) for species in TEST_SPECIES])

rule _all_genomes:
    input:
        expand(str(project_dir/"genomes"/"{species}.fna.lz4"), species = SPECIES_0701)

"""
Gene annotation
"""
rule run_prokka:
    input:
        str(genomes_dir/'{genome}.fna.lz4')
    output:
        faa = str(prokka_dir/'{genome}'/'{genome}.faa'),
        ffn = str(prokka_dir/'{genome}'/'{genome}.ffn'),
        fna = str(prokka_dir/'{genome}'/'{genome}.fna'),
        genes = str(prokka_dir/'{genome}'/'{genome}.genes')
    params:
        outdir = str(prokka_dir/'{genome}'),
        prefix = "{genome}",
        tsv = str(prokka_dir/'{genome}'/'{genome}.tsv'),
        fna = str(genomes_dir/'{genome}.fna')
    shell:
        """
        lz4 -d {input} && \
        prokka --kingdom Bacteria --outdir {params.outdir} --prefix {params.prefix} \
        --locustag {params.prefix} --centre X --compliant --force {params.fna} &&
        mv {params.tsv} {output.genes} &&
        rm {params.fna}
        """

rule _all_prokka:
    input:
        expand(str(prokka_dir/'{genome}'/'{genome}.genes'), genome = GENOMES)

"""
Pan-genome
- pangeomes/{species}/genes.ffn: all genes from specificed genomes
- pangeomes/{species}/centroids.ff: gene sequences from 99%% identity gene clusters
- pangeomes/{species}/gene_info.txt: information for all genes from genes.ffn
"""

## This should be a faster way to do this. But let's keep it work now.
## might run into command arguments too long if do it in a Snakemake way
rule write_genes:
    input:
        genomes = expand(str(prokka_dir/'{genome}'/'{genome}.ffn'), genome = GENOMES),
        mapfile = mapfile_fp
    output:
        genes = str(pangenomes_dir/"{species}"/"genes.ffn")
    params:
        sp_id = "{species}",
        genome_fp = str(prokka_dir)
    run:
        genomes = SPECIES[params['sp_id']]
        genes = {}
        stats = {}
        stats['genes'] = 0
        for genome in genomes:
            genome_file = '%s/%s/%s.ffn' % (params['genome_fp'], genome, genome)
            for rec in Bio.SeqIO.parse(genome_file, 'fasta'):
                if str(rec.seq) == '' or str(rec.id) in ['', '|']:
                    continue
                else:
                    genes[rec.id] = str(rec.seq).upper()
                    stats['genes'] += 1
        ## write genes
        with open(output['genes'], 'w') as file:
            for geneid, geneseq in genes.items():
                file.write('>%s\n%s\n' % (geneid, geneseq))

rule uclust_genes_99:
    input:
        genes = str(pangenomes_dir/"{species}"/"genes.ffn")
    output:
        centroids = str(pangenomes_dir/"{species}"/"temp"/"centroids.99.ffn"),
        uc = str(pangenomes_dir/"{species}"/"temp"/"uclust.99.txt")
    params:
        pid = 0.99
    threads:
        46
    shell:
        """
        vsearch -cluster_fast {input.genes} -id {params.pid} -threads {threads} \
                -centroids {output.centroids} -uc {output.uc}
        """

rule uclust_genes:
    input:
        str(pangenomes_dir/"{species}"/"temp"/"centroids.99.ffn")
    output:
        centroids = str(pangenomes_dir/"{species}"/"temp"/"centroids.{pid}.ffn"),
        uc = str(pangenomes_dir/"{species}"/"temp"/"uclust.{pid}.txt")
    threads:
        4
    shell:
        """
        calc(){{ awk "BEGIN {{ print "$*" }}"; }}
        pid=`calc {wildcards.pid}/100`
        vsearch -cluster_fast {input} -id $pid -threads {threads} \
                -centroids {output.centroids} -uc {output.uc}
        """

rule _all_cluster:
    input:
        expand(str(pangenomes_dir/"{species}"/"temp"/"centroids.{pid}.ffn"), pid=[95, 90, 85, 80, 75], species = TEST_SPECIES)

def parse_uclust(inpath):
    """ Yield formated records from UCLUST outputfile """
    fields = ['type', 'cluster_id', 'size', 'pid', 'strand', 'skip1', 'skip2', 'skip3', 'gene_id', 'centroid_id']
    with utility.iopen(inpath) as infile:
        for index, line in enumerate(infile):
            values = line.rstrip('\n').split('\t')
            record = dict([(f, v) for f, v in zip(fields, values)])
            yield record

rule store_gene_info:
    input:
        uclust = expand(str(pangenomes_dir/"{{species}}"/"temp"/"uclust.{pid}.txt"), pid=[95, 90, 85, 80, 75]),
        genomes = expand(str(prokka_dir/'{genome}'/'{genome}.ffn'), genome = GENOMES)
    output:
        str(pangenomes_dir/"{species}"/"gene_info.txt")
    params:
        tmp_dir = str(pangenomes_dir/"{species}"/"temp"),
        out_dir = str(pangenomes_dir/"{species}"),
        sp_id = "{species}",
        genome_fp = str(prokka_dir)
    run:
        genes = defaultdict(lambda: defaultdict(int))
        stats = {}

        """ store_gene_info """
        for pid in [99, 95, 90, 85, 80, 75]:
            stats['centroids_%s' % pid] = 0
            for r in parse_uclust('%s/uclust.%s.txt' % (params['tmp_dir'], pid)):
                if r['type'] == 'H': ## non-centroids
                    genes[r['gene_id']]["cluster_id_%s" % str(pid)] = r['cluster_id']
                    genes[r['gene_id']]["centroid_id_%s" % str(pid)] = r['centroid_id']
                elif r['type'] == 'S': ## centroids
                    genes[r['gene_id']]["cluster_id_%s" % str(pid)] = r['cluster_id']
                    genes[r['gene_id']]["centroid_id_%s" % str(pid)] = r['gene_id']
                    stats['centroids_%s' % pid] += 1
                else:
                    continue

        """ store_cluster_membership: Map gene to 99% ID centroids at each clustering %ID cutoff """
        for gene in genes.values():
            gene["centroid_99"] = gene["centroid_id_99"]
            gene["centroid_95"] = genes[ gene["centroid_99"] ]["centroid_id_95"]
            gene["centroid_90"] = genes[ gene["centroid_99"] ]["centroid_id_90"]
            gene["centroid_85"] = genes[ gene["centroid_99"] ]["centroid_id_85"]
            gene["centroid_80"] = genes[ gene["centroid_99"] ]["centroid_id_80"]
            gene["centroid_75"] = genes[ gene["centroid_99"] ]["centroid_id_75"]

        genomes = SPECIES[params['sp_id']]
        stats = {}
        stats['genes'] = 0
        for genome in genomes:
            genome_file = '%s/%s/%s.ffn' % (params['genome_fp'], genome, genome)
            for rec in Bio.SeqIO.parse(genome_file, 'fasta'):
                if str(rec.seq) == '' or str(rec.id) in ['', '|']:
                    continue
                else:
                    genes[rec.id]["genome_id"] = genome
                    genes[rec.id]["gene_length"] = len(rec.seq)
                    stats['genes'] += 1

        """ write_gene_info """
        file = utility.iopen(output[0], 'w')
        header = ['gene_id', 'genome_id', 'gene_length', 'centroid_99', 'centroid_95', 'centroid_90', 'centroid_85', 'centroid_80', 'centroid_75']
        file.write('\t'.join(header)+'\n')
        for gene_id in sorted(genes.keys()):
            g = genes[gene_id]
            values = [gene_id, g['genome_id'],g['gene_length'],g["centroid_99"], g["centroid_95"], g["centroid_90"], g["centroid_85"], g["centroid_80"], g["centroid_75"]]
            file.write('\t'.join(str(_) for _ in values) + '\n')
        file.close()

rule copy_centroids:
    input:
        str(pangenomes_dir/"{species}"/"temp"/"centroids.99.ffn")
    output:
        str(pangenomes_dir/"{species}"/"centroids.ffn")
    shell:
        "cp {input} {output}"

rule _all_pan:
    input:
        expand(str(pangenomes_dir/"{species}"/"gene_info.txt"), species = TEST_SPECIES)

"""
Marker genes database: search markder gene HMMs against pangenomes
"""
rule hmm_search:
    input:
        faa = str(prokka_dir/'{genome}'/'{genome}.faa'),
        phyeco = phyeco_hmm_fp
    output:
        str(project_dir/"marker_genes"/"temp"/"{genome}.hmmsearch")
    threads: 1
    shell:
        """
        hmmsearch --noali --cpu {threads} --domtblout {output} {input.phyeco} {input.faa}
        """

def parse_fasta(p_in):
    """" Lookup of seq_id to sequence for PATRIC genes """
    seqs = {}
    infile = utility.iopen(p_in)
    for r in Bio.SeqIO.parse(infile, "fasta"):
        seqs[r.id] = str(r.seq).upper()
    infile.close()
    return seqs

def parse_hmmsearch(p_in):
    """ Parse HMMER domblout files. Return data-type formatted dictionary """
    f_in = utility.iopen(p_in)
    for line in f_in:
        if line[0] == '#': continue
        x = line.rstrip().split()
        query = x[0]
        target = x[3]
        evalue = float(x[12])
        qcov = (int(x[20]) - int(x[19]) + 1)/float(x[2])
        tcov = (int(x[16]) - int(x[15]) + 1)/float(x[5])
        yield {'query':query, 'target':target, 'evalue':evalue, 'qcov':qcov, 'tcov':tcov, 'qlen':int(x[2]), 'tlen':int(x[5])}

def find_hits(inpath, max_evalue, min_cov):
    hits = {}
    for r in parse_hmmsearch(inpath):
        if r['evalue'] > max_evalue:
            continue
        elif min(r['qcov'], r['tcov']) < min_cov:
            continue
        if r['target'] not in hits:
            hits[r['target']] = r
        elif r['evalue'] < hits[r['target']]['evalue']:
            hits[r['target']] = r
    return list(hits.values())

def parse_mapping_file(mapfile):
    infile = utility.iopen(mapfile)
    fields = next(infile).rstrip('\n').split('\t')
    for line in infile:
        values = line.rstrip('\n').split('\t')
        record = dict([(f,v) for f, v in zip(fields, values)])
        yield record

rule build_marker_db:
    input:
        ffn = str(prokka_dir/'{genome}'/'{genome}.ffn'),
        hmm_path = str(project_dir/"marker_genes"/"temp"/"{genome}.hmmsearch")
    output:
        fasta = str(project_dir/"marker_genes"/"temp"/"{genome}.phyeco.fa"),
        info = str(project_dir/"marker_genes"/"temp"/"{genome}.phyeco.map")
    params:
        max_evalue = 1e-5,
        min_cov = 0.00
    run:
        genome_id = wildcards['genome']
        species_id = GENOMES_DICT[genome_id]

        ffn = parse_fasta(input['ffn'])

        with open(output['fasta'], "w") as ofasta, open(output['info'], "w") as oinfo:
            for h in find_hits(input['hmm_path'], params['max_evalue'], params['min_cov']):
                gene = ffn[h['query']].upper()
                info = [species_id, genome_id, h['query'], len(gene), h['target']]
                oinfo.write('\t'.join([str(_) for _ in info]) + '\n')
                if genome_id in list(SPECIES.keys()):
                    ofasta.write('>%s\n%s\n' % (h['query'], gene))

rule _all_hmm:
    input:
        expand(str(project_dir/"marker_genes"/"temp"/"{genome}.phyeco.fa"), genome = GENOMES)

rule build_hsblastn_db:
    input:
        str(project_dir/"marker_genes"/"phyeco.fa")
    output:
        str(project_dir/"marker_genes"/"phyeco.fa.sa")
    shell:
        "hs-blastn index {input}"

## I don't have the representative genomes database....I need to quickly go over this this afternoon
## after the marker genes database
